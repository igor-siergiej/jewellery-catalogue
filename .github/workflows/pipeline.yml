name: CI/CD Pipeline 

# Comprehensive caching strategy for self-hosted runner:
# - Yarn dependencies & cache (.yarn/cache, node_modules)
# - TypeScript build outputs (build/, dist/, *.tsbuildinfo)
# - ESLint cache (.eslintcache)
# - Playwright browsers (persistent install at /opt/playwright-browsers)
# - Docker build layers (/tmp/.buildx-cache)

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  test:
    runs-on: [self-hosted, linux, x64]
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Enable Corepack
        run: corepack enable

      - name: Cache Yarn dependencies
        uses: actions/cache@v4
        with:
          path: |
            node_modules
            packages/*/node_modules
            .yarn/cache
            .yarn/unplugged
            .yarn/install-state.gz
          key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock', 'package.json') }}
          restore-keys: |
            ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
            ${{ runner.os }}-yarn-

      - name: Cache TypeScript build outputs
        uses: actions/cache@v4
        with:
          path: |
            packages/*/build
            packages/*/dist
            **/*.tsbuildinfo
          key: ${{ runner.os }}-ts-build-${{ hashFiles('**/tsconfig*.json', 'packages/*/src/**/*.ts', 'packages/*/src/**/*.tsx') }}
          restore-keys: |
            ${{ runner.os }}-ts-build-

      - name: Cache ESLint
        uses: actions/cache@v4
        with:
          path: |
            .eslintcache
            packages/*/.eslintcache
          key: ${{ runner.os }}-eslint-${{ hashFiles('**/eslint.config.*', '**/.eslintrc.*', 'packages/*/src/**/*.ts', 'packages/*/src/**/*.tsx') }}
          restore-keys: |
            ${{ runner.os }}-eslint-

      - name: Install dependencies
        run: yarn install --immutable

      - name: Lint code
        run: yarn eslint . --cache --cache-location .eslintcache

      - name: Type check
        run: yarn tsc --noEmit --composite false

      - name: Build API package
        run: yarn workspace @jewellery-catalogue/api build

      - name: Build Auth package
        run: yarn workspace @jewellery-catalogue/auth build

      - name: Build Web package
        run: yarn workspace @jewellery-catalogue/web build

  deploy-staging:
    needs: test
    runs-on: [self-hosted, linux, x64]
    if: github.ref == 'refs/heads/main'
    outputs:
      staging-url: ${{ steps.staging-info.outputs.url }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Check staging .env file exists
        run: |
          if [ ! -f .env.staging ]; then
            echo "Error: .env.staging file not found!"
            echo "Please create .env.staging from env.staging.example"
            echo "See STAGING_README.md for details"
            exit 1
          fi

      - name: Clean staging databases
        run: |
          # Stop staging services
          docker compose -f docker-compose.staging.yml down -v
          
          # Remove any existing staging volumes to ensure clean state
          docker volume rm jewellery-catalogue-staging-mongo-data 2>/dev/null || true
          docker volume rm jewellery-catalogue-staging-auth-mongo-data 2>/dev/null || true
          docker volume rm jewellery-catalogue-staging-minio-data 2>/dev/null || true
          docker volume rm jewellery-catalogue-staging-api-data 2>/dev/null || true
          docker volume rm jewellery-catalogue-staging-auth-data 2>/dev/null || true

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-docker-staging-${{ hashFiles('**/Dockerfile', 'docker-compose.staging.yml', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-docker-staging-
            ${{ runner.os }}-docker-

      - name: Build staging Docker images
        run: |
          # Enable buildkit for better caching
          export DOCKER_BUILDKIT=1
          export COMPOSE_DOCKER_CLI_BUILD=1
          docker compose -f docker-compose.staging.yml build

      - name: Deploy to staging
        run: |
          docker compose -f docker-compose.staging.yml up -d

      - name: Wait for staging services to be ready
        run: |
          timeout 60 bash -c 'until curl -f http://localhost:5001/health 2>/dev/null; do sleep 5; done' || echo "API health check timeout"
          timeout 60 bash -c 'until curl -f http://localhost:5002/health 2>/dev/null; do sleep 5; done' || echo "Auth health check timeout"
          timeout 60 bash -c 'until curl -f http://localhost:8082 2>/dev/null; do sleep 5; done' || echo "Web health check timeout"

      - name: Set staging info
        id: staging-info
        run: |
          echo "url=http://localhost:8082" >> $GITHUB_OUTPUT

  e2e-tests:
    needs: deploy-staging
    runs-on: [self-hosted, linux, x64]

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Enable Corepack
        run: corepack enable

      - name: Cache Yarn dependencies
        uses: actions/cache@v4
        with:
          path: |
            node_modules
            packages/*/node_modules
            .yarn/cache
            .yarn/unplugged
            .yarn/install-state.gz
          key: ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock', 'package.json') }}
          restore-keys: |
            ${{ runner.os }}-yarn-${{ hashFiles('**/yarn.lock') }}
            ${{ runner.os }}-yarn-

      - name: Cache TypeScript build outputs
        uses: actions/cache@v4
        with:
          path: |
            packages/*/build
            packages/*/dist
            **/*.tsbuildinfo
          key: ${{ runner.os }}-ts-build-${{ hashFiles('**/tsconfig*.json', 'packages/*/src/**/*.ts', 'packages/*/src/**/*.tsx') }}
          restore-keys: |
            ${{ runner.os }}-ts-build-

      - name: Install dependencies
        run: yarn install --immutable

      - name: Setup Playwright browsers (one-time install on runner)
        run: |
          # Use persistent location on self-hosted runner
          export PLAYWRIGHT_BROWSERS_PATH=/opt/playwright-browsers
          
          # Check if browsers are already installed
          if [ -d "$PLAYWRIGHT_BROWSERS_PATH" ] && [ "$(ls -A $PLAYWRIGHT_BROWSERS_PATH 2>/dev/null)" ]; then
            echo "âœ… Playwright browsers already installed in $PLAYWRIGHT_BROWSERS_PATH"
            echo "Checking browser versions..."
            cd packages/web && yarn playwright --version
          else
            echo "ðŸ“¦ Installing Playwright browsers (one-time setup)..."
            sudo mkdir -p $PLAYWRIGHT_BROWSERS_PATH
            sudo chown $(whoami):$(whoami) $PLAYWRIGHT_BROWSERS_PATH
            cd packages/web && yarn playwright install
            echo "âœ… Playwright browsers installed to $PLAYWRIGHT_BROWSERS_PATH"
          fi
        env:
          PLAYWRIGHT_BROWSERS_PATH: /opt/playwright-browsers

      - name: Run E2E Tests against Staging
        run: cd packages/web && yarn playwright test --config=playwright-e2e.config.ts
        env:
          PLAYWRIGHT_BROWSERS_PATH: /opt/playwright-browsers
          STAGING_BASE_URL: ${{ needs.deploy-staging.outputs.staging-url }}

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-playwright-report
          path: packages/web/playwright-report/
          retention-days: 30

      - name: Upload E2E test screenshots
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-playwright-test-results
          path: packages/web/test-results/
          retention-days: 30

  deploy-production:
    needs: [deploy-staging, e2e-tests]
    runs-on: [self-hosted, linux, x64]
    if: github.ref == 'refs/heads/main' && success()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Write production .env from Secrets
        run: |
          echo "VITE_API_URL=${{ secrets.VITE_API_URL }}" > .env
          echo "VITE_AUTH_URL=${{ secrets.VITE_AUTH_URL }}" >> .env
          echo "API_CONNECTION_URI=${{ secrets.API_CONNECTION_URI }}" >> .env
          echo "API_DATABASE_NAME=${{ secrets.API_DATABASE_NAME }}" >> .env
          echo "API_PORT=${{ secrets.API_PORT }}" >> .env
          echo "AUTH_CONNECTION_URI=${{ secrets.AUTH_CONNECTION_URI }}" >> .env
          echo "AUTH_DATABASE_NAME=${{ secrets.AUTH_DATABASE_NAME }}" >> .env
          echo "AUTH_PORT=${{ secrets.AUTH_PORT }}" >> .env
          echo "JWT_SECRET=${{ secrets.JWT_SECRET }}" >> .env
          echo "ACCESS_TOKEN_EXPIRY=${{ secrets.ACCESS_TOKEN_EXPIRY }}" >> .env
          echo "REFRESH_TOKEN_EXPIRY=${{ secrets.REFRESH_TOKEN_EXPIRY }}" >> .env
          echo "SECURE=${{ secrets.SECURE }}" >> .env
          echo "SAME_SITE=${{ secrets.SAME_SITE }}" >> .env
          echo "BUCKET_NAME=${{ secrets.BUCKET_NAME }}" >> .env
          echo "BUCKET_ACCESS_KEY=${{ secrets.BUCKET_ACCESS_KEY }}" >> .env
          echo "BUCKET_SECRET_KEY=${{ secrets.BUCKET_SECRET_KEY }}" >> .env
          echo "BUCKET_PORT=${{ secrets.BUCKET_PORT }}" >> .env
          echo "BUCKET_ENDPOINT=${{ secrets.BUCKET_ENDPOINT }}" >> .env
          echo "MINIO_ROOT_USER=${{ secrets.MINIO_ROOT_USER }}" >> .env
          echo "MINIO_ROOT_PASSWORD=${{ secrets.MINIO_ROOT_PASSWORD }}" >> .env

      - name: Cache Docker layers
        uses: actions/cache@v4
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-docker-prod-${{ hashFiles('**/Dockerfile', 'docker-compose.yml', '**/package.json') }}
          restore-keys: |
            ${{ runner.os }}-docker-prod-
            ${{ runner.os }}-docker-staging-
            ${{ runner.os }}-docker-

      - name: Build production Docker images
        run: |
          # Enable buildkit for better caching
          export DOCKER_BUILDKIT=1
          export COMPOSE_DOCKER_CLI_BUILD=1
          docker compose build

      - name: Deploy to production
        run: |
          docker compose down
          docker compose up -d

      - name: Cleanup staging
        run: |
          # Clean up staging environment after successful production deployment
          docker compose -f docker-compose.staging.yml down -v

